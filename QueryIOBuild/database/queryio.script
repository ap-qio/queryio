SET DATABASE UNIQUE NAME HSQLDB4DD806ADBC
SET DATABASE GC 0
SET DATABASE DEFAULT RESULT MEMORY ROWS 0
SET DATABASE EVENT LOG LEVEL 0
SET DATABASE TRANSACTION CONTROL LOCKS
SET DATABASE DEFAULT ISOLATION LEVEL READ COMMITTED
SET DATABASE TRANSACTION ROLLBACK ON CONFLICT TRUE
SET DATABASE TEXT TABLE DEFAULTS ''
SET DATABASE SQL NAMES FALSE
SET DATABASE SQL REFERENCES FALSE
SET DATABASE SQL SIZE TRUE
SET DATABASE SQL TYPES FALSE
SET DATABASE SQL TDC DELETE TRUE
SET DATABASE SQL TDC UPDATE TRUE
SET DATABASE SQL TRANSLATE TTI TYPES TRUE
SET DATABASE SQL CONCAT NULLS TRUE
SET DATABASE SQL UNIQUE NULLS TRUE
SET DATABASE SQL CONVERT TRUNCATE TRUE
SET DATABASE SQL AVG SCALE 0
SET DATABASE SQL DOUBLE NAN TRUE
SET DATABASE SQL SYNTAX MYS TRUE
SET FILES WRITE DELAY 500 MILLIS
SET FILES BACKUP INCREMENT TRUE
SET FILES CACHE SIZE 10000
SET FILES CACHE ROWS 50000
SET FILES SCALE 32
SET FILES LOB SCALE 32
SET FILES DEFRAG 0
SET FILES NIO TRUE
SET FILES NIO SIZE 256
SET FILES LOG TRUE
SET FILES LOG SIZE 50
CREATE USER SA PASSWORD DIGEST 'd41d8cd98f00b204e9800998ecf8427e'
ALTER USER SA SET LOCAL TRUE
CREATE USER $SysDBUser$ PASSWORD $SysDBPass$
CREATE SCHEMA PUBLIC AUTHORIZATION DBA
SET SCHEMA PUBLIC
CREATE MEMORY TABLE PUBLIC.HOSTS(ID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,HOSTIP VARCHAR(255),INSTALLDIR VARCHAR(255),STATUS VARCHAR(255),RACKNAME VARCHAR(255),AGENTPORT VARCHAR(10),MONITOR BOOLEAN,IS_WINDOWS BOOLEAN DEFAULT FALSE)
ALTER TABLE PUBLIC.HOSTS ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.NODES(ID VARCHAR(255) NOT NULL PRIMARY KEY,NODETYPE VARCHAR(255),HOSTID INTEGER,STATUS VARCHAR(255),JMXPORT VARCHAR(10),SERVICESTATUS VARCHAR(255),HIVESERVICESTATUS VARCHAR(255),MONITOR BOOLEAN)
CREATE MEMORY TABLE PUBLIC.QUERYIOSERVICES(NODEID VARCHAR(255) NOT NULL,NODETYPE VARCHAR(255),STATUS VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.HASTATUS(ACTIVENODEID VARCHAR(255),STANDBYNODEID VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.MIGRATIONSTATUS(ID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,NAMENODEID VARCHAR(255),ISIMPORTTYPE BOOLEAN,TITLE VARCHAR(1024),STARTTIME TIMESTAMP,ENDTIME TIMESTAMP,DATASTORE VARCHAR(100),DESTINATIONPATH VARCHAR(8000),SOURCEPATH VARCHAR(8000),PROGRESS DOUBLE,STATUS VARCHAR(250),ISSECURE BOOLEAN,UNZIP BOOLEAN,COMPRESSION_TYPE VARCHAR(64),ENCRYPTION_TYPE VARCHAR(64))
ALTER TABLE PUBLIC.MIGRATIONSTATUS ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.SNAPSHOTS(ID VARCHAR(32) NOT NULL PRIMARY KEY,HOSTNAME VARCHAR(32),LOCATION VARCHAR(125),STATUS VARCHAR(32),TIME TIMESTAMP)
CREATE MEMORY TABLE PUBLIC.NODESTATUS(NODEID VARCHAR(255),TIME BIGINT,STATUS INTEGER)
CREATE MEMORY TABLE PUBLIC.NODESTATUS_CONSOLIDATEDDATA(NODEID VARCHAR(255),TIME BIGINT,STATUS INTEGER)
CREATE MEMORY TABLE PUBLIC.VOLUMES(NODEID VARCHAR(255) NOT NULL,DISK VARCHAR(255) NOT NULL,PATH VARCHAR(255) NOT NULL)
CREATE MEMORY TABLE PUBLIC.DISKMONITOREDDATA(HOSTID INTEGER NOT NULL,DISKNAME VARCHAR(255),DSKBYTEREADSPERSEC DOUBLE,DSKBYTEWRITESPERSEC DOUBLE,DISKHEALTHSTATUS VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.USERS(ID INTEGER GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL,USERNAME VARCHAR(20) NOT NULL PRIMARY KEY,FIRSTNAME VARCHAR(255) NOT NULL,LASTNAME VARCHAR(255) NOT NULL,PASSWORD VARCHAR(255) NOT NULL,EMAIL VARCHAR(255) NOT NULL,UNIQUE(ID))
ALTER TABLE PUBLIC.USERS ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.ROLES(ROLENAME VARCHAR(20) NOT NULL)
CREATE MEMORY TABLE PUBLIC.USER_ROLES(USERNAME VARCHAR(20) NOT NULL,ROLENAME VARCHAR(20) NOT NULL)
CREATE MEMORY TABLE PUBLIC.HOST_SYSTEM_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL,GROUPNAME VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.HOST_LIVE_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.NAMENODE_SYSTEM_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL,GROUPNAME VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.DATANODE_SYSTEM_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL,GROUPNAME VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.NAMENODE_LIVE_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.DATANODE_LIVE_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.RESOURCE_MANAGER_SYSTEM_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL,GROUPNAME VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.RESOURCE_MANAGER_LIVE_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.NODE_MANAGER_SYSTEM_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL,GROUPNAME VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.NODE_MANAGER_LIVE_ATTRIBUTES(ATTRIBUTENAME VARCHAR(120) NOT NULL,OBJECTNAME VARCHAR(120) NOT NULL,COLUMNNAME VARCHAR(120) NOT NULL,DESCRIPTION VARCHAR(120) NOT NULL,DATATYPE VARCHAR(120) NOT NULL)
CREATE MEMORY TABLE PUBLIC.BILLING_REPORT_DATA(BILLINGID VARCHAR(128) PRIMARY KEY,DATATIMESTAMP TIMESTAMP NOT NULL,USEDSTORAGE BIGINT NOT NULL,BYTESREAD BIGINT NOT NULL,BYTESWRITTEN BIGINT NOT NULL,PUTREQUESTS BIGINT NOT NULL,GETREQUESTS BIGINT NOT NULL,LISTREQUESTS BIGINT NOT NULL,DELETEREQUESTS BIGINT NOT NULL)
CREATE MEMORY TABLE PUBLIC.HIVETABLES(TABLENAME VARCHAR(255) NOT NULL,NAMENODEID VARCHAR(255) NOT NULL,RMID VARCHAR(255),FILE_TYPE VARCHAR(255),FILE_NAME VARCHAR(2550))
CREATE MEMORY TABLE PUBLIC.DATABASE_DATASOURCE(ID VARCHAR(120) NOT NULL,DRIVERCLASS VARCHAR(255),CONNECTIONURL VARCHAR(512),USERNAME VARCHAR(255),PASSWORD VARCHAR(255),DATABASEDRIVERJAR VARCHAR(1280),MAXCONN INTEGER,MAXIDLECONN INTEGER,WAITTIME INTEGER)
CREATE MEMORY TABLE PUBLIC.BILLING_CONFIG_DATA(USEDSTORAGERATE DECIMAL(128) NOT NULL,BYTESREADRATE DECIMAL(128) NOT NULL,BYTESWRITTENRATE DECIMAL(128) NOT NULL,PUTREQUESTSRATE DECIMAL(128) NOT NULL,GETREQUESTSRATE DECIMAL(128) NOT NULL,LISTREQUESTSRATE DECIMAL(128) NOT NULL,DELETEREQUESTSRATE DECIMAL(128) NOT NULL)
CREATE MEMORY TABLE PUBLIC.LAST_CONSOLIDATE_LOG(ID VARCHAR(225),LAST_CONSOLIDATE_LOG_TIME TIMESTAMP NOT NULL)
CREATE MEMORY TABLE PUBLIC.NOTIFICATIONSETTINGS(EMAIL_ENABLED BOOLEAN,EMAIL_SENDERNAME VARCHAR(255),EMAIL_SENDERADD VARCHAR(255),SECUREDPROTOCOL BOOLEAN,EMAIL_SMTPSERVER VARCHAR(255),EMAIL_SMTPPORT VARCHAR(255),AUTHREQUIRED BOOLEAN,EMAIL_USERNAME VARCHAR(255),EMAIL_PASSWORD VARCHAR(255),SMS_ENABLED BOOLEAN,SMS_NUMBER VARCHAR(255),SMS_SERIALPORT VARCHAR(255),SMS_MANUFACTURER VARCHAR(255),SMS_MODEL VARCHAR(255),SMS_SELECTEDMODEL VARCHAR(255),SMS_BAUDRATE VARCHAR(255),LOG_ENABLED BOOLEAN,LOG_FILEPATH VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.HADOOPCONFIG(TYPE VARCHAR(50),HADOOPKEY VARCHAR(100),DEFAULT_VALUE VARCHAR(1000),DESCRIPTION VARCHAR(1000))
CREATE MEMORY TABLE PUBLIC.HADOOPSERVICES(NODEID VARCHAR(255),TIMEOFCALL TIMESTAMP,TYPE VARCHAR(50),OUTPUTFILEPATH VARCHAR(1000),STATUS VARCHAR(50))
CREATE MEMORY TABLE PUBLIC.RULES(RULEID VARCHAR(128) PRIMARY KEY,NODEID VARCHAR(255) NOT NULL,IGNORERULE BOOLEAN NOT NULL,SEVERITY VARCHAR(32) NOT NULL,ALERTRAISEDNOTIFMSG VARCHAR(255) NOT NULL,ALERTRAISEDNOTIFSUB VARCHAR(128) NOT NULL,ALERTRESETNOTIFMSG VARCHAR(255) NOT NULL,ALERTRESETNOTIFSUB VARCHAR(128) NOT NULL,NOTIFTYPE VARCHAR(128) NOT NULL)
CREATE MEMORY TABLE PUBLIC.RULEEXPRESSIONS(RULEID VARCHAR(32) NOT NULL,RULE_CONDITION VARCHAR(16) NOT NULL,EXPVALUE INTEGER NOT NULL,STARTTIME VARCHAR(64),ENDTIME VARCHAR(64),DURATION INTEGER,ATTRIBUTENAME VARCHAR(255) NOT NULL,NODEID VARCHAR(255) NOT NULL)
CREATE MEMORY TABLE PUBLIC.ALERTS(RULEID VARCHAR(32) NOT NULL,NODEID VARCHAR(255) NOT NULL,SEVERITY VARCHAR(32) NOT NULL,STARTTIME TIMESTAMP NOT NULL,ENDTIME TIMESTAMP)
CREATE MEMORY TABLE PUBLIC.ALERTATTRIBUTES(RULEID VARCHAR(32) NOT NULL,NODEID VARCHAR(255) NOT NULL,ALERTTIME TIMESTAMP NOT NULL,ATTRIBUTENAME VARCHAR(255) NOT NULL)
CREATE MEMORY TABLE PUBLIC.ATTRIBUTESTATE(STATE VARCHAR(64) NOT NULL,ATTRIBUTENAME VARCHAR(255) NOT NULL,NODEID VARCHAR(255) NOT NULL,STARTTIME TIMESTAMP NOT NULL,ENDTIME TIMESTAMP)
CREATE MEMORY TABLE PUBLIC.QRTZ_JOB_DETAILS(SCHED_NAME VARCHAR(120) NOT NULL,JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,DESCRIPTION VARCHAR(250),JOB_CLASS_NAME VARCHAR(250) NOT NULL,IS_DURABLE BOOLEAN NOT NULL,IS_NONCONCURRENT BOOLEAN NOT NULL,IS_UPDATE_DATA BOOLEAN NOT NULL,REQUESTS_RECOVERY BOOLEAN NOT NULL,JOB_DATA VARBINARY(16000),PRIMARY KEY(SCHED_NAME,JOB_NAME,JOB_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_TRIGGERS(SCHED_NAME VARCHAR(120) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,DESCRIPTION VARCHAR(250),NEXT_FIRE_TIME NUMERIC(13),PREV_FIRE_TIME NUMERIC(13),PRIORITY INTEGER,TRIGGER_STATE VARCHAR(16) NOT NULL,TRIGGER_TYPE VARCHAR(8) NOT NULL,START_TIME NUMERIC(13) NOT NULL,END_TIME NUMERIC(13),CALENDAR_NAME VARCHAR(200),MISFIRE_INSTR NUMERIC(2),JOB_DATA VARBINARY(16000),PRIMARY KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP),FOREIGN KEY(SCHED_NAME,JOB_NAME,JOB_GROUP) REFERENCES PUBLIC.QRTZ_JOB_DETAILS(SCHED_NAME,JOB_NAME,JOB_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_SIMPLE_TRIGGERS(SCHED_NAME VARCHAR(120) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,REPEAT_COUNT NUMERIC(7) NOT NULL,REPEAT_INTERVAL NUMERIC(12) NOT NULL,TIMES_TRIGGERED NUMERIC(10) NOT NULL,PRIMARY KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP),FOREIGN KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES PUBLIC.QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_CRON_TRIGGERS(SCHED_NAME VARCHAR(120) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,CRON_EXPRESSION VARCHAR(120) NOT NULL,TIME_ZONE_ID VARCHAR(80),PRIMARY KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP),FOREIGN KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES PUBLIC.QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_SIMPROP_TRIGGERS(SCHED_NAME VARCHAR(120) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,STR_PROP_1 VARCHAR(512),STR_PROP_2 VARCHAR(512),STR_PROP_3 VARCHAR(512),INT_PROP_1 NUMERIC(9),INT_PROP_2 NUMERIC(9),LONG_PROP_1 NUMERIC(13),LONG_PROP_2 NUMERIC(13),DEC_PROP_1 NUMERIC(13,4),DEC_PROP_2 NUMERIC(13,4),BOOL_PROP_1 BOOLEAN,BOOL_PROP_2 BOOLEAN,PRIMARY KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP),FOREIGN KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES PUBLIC.QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_BYTEA_TRIGGERS(SCHED_NAME VARCHAR(120) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,BYTEA_DATA VARBINARY(16000),PRIMARY KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP),FOREIGN KEY(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP) REFERENCES PUBLIC.QRTZ_TRIGGERS(SCHED_NAME,TRIGGER_NAME,TRIGGER_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_CALENDARS(SCHED_NAME VARCHAR(120) NOT NULL,CALENDAR_NAME VARCHAR(200) NOT NULL,CALENDAR VARBINARY(16000) NOT NULL,PRIMARY KEY(SCHED_NAME,CALENDAR_NAME))
CREATE MEMORY TABLE PUBLIC.QRTZ_PAUSED_TRIGGER_GRPS(SCHED_NAME VARCHAR(120) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,PRIMARY KEY(SCHED_NAME,TRIGGER_GROUP))
CREATE MEMORY TABLE PUBLIC.QRTZ_FIRED_TRIGGERS(SCHED_NAME VARCHAR(120) NOT NULL,ENTRY_ID VARCHAR(95) NOT NULL,TRIGGER_NAME VARCHAR(200) NOT NULL,TRIGGER_GROUP VARCHAR(200) NOT NULL,INSTANCE_NAME VARCHAR(200) NOT NULL,FIRED_TIME NUMERIC(13) NOT NULL,PRIORITY INTEGER NOT NULL,STATE VARCHAR(16) NOT NULL,JOB_NAME VARCHAR(200),JOB_GROUP VARCHAR(200),IS_NONCONCURRENT BOOLEAN,REQUESTS_RECOVERY BOOLEAN,PRIMARY KEY(SCHED_NAME,ENTRY_ID))
CREATE MEMORY TABLE PUBLIC.QRTZ_SCHEDULER_STATE(SCHED_NAME VARCHAR(120) NOT NULL,INSTANCE_NAME VARCHAR(200) NOT NULL,LAST_CHECKIN_TIME NUMERIC(13) NOT NULL,CHECKIN_INTERVAL NUMERIC(13) NOT NULL,PRIMARY KEY(SCHED_NAME,INSTANCE_NAME))
CREATE MEMORY TABLE PUBLIC.QRTZ_LOCKS(SCHED_NAME VARCHAR(120) NOT NULL,LOCK_NAME VARCHAR(40) NOT NULL,PRIMARY KEY(SCHED_NAME,LOCK_NAME))
CREATE MEMORY TABLE PUBLIC.TRIGGERED_SCHEDULEJOB_STATE(ID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,JOB_NAME VARCHAR(200) NOT NULL,JOB_GROUP VARCHAR(200) NOT NULL,STARTTIME TIMESTAMP,ENDTIME TIMESTAMP,STATUS VARCHAR(125),REASON_FOR_FAILURE VARCHAR(120))
ALTER TABLE PUBLIC.TRIGGERED_SCHEDULEJOB_STATE ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.TASKS(ID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,TASK_TIMESTAMP TIMESTAMP NOT NULL,TASK_TYPE VARCHAR(25) NOT NULL,BUCKET_NAME VARCHAR(125),OBJECT_NAME VARCHAR(125),REPLICATION_ATTEMPTS INTEGER DEFAULT 0)
ALTER TABLE PUBLIC.TASKS ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.FAILED_TASKS(ID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,TASK_TIMESTAMP TIMESTAMP NOT NULL,TASK_TYPE VARCHAR(25) NOT NULL,BUCKET_NAME VARCHAR(125),OBJECT_NAME VARCHAR(125),REPLICATION_ATTEMPTS INTEGER DEFAULT 0)
ALTER TABLE PUBLIC.FAILED_TASKS ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.GROUPS(NAME VARCHAR(125),ID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY)
ALTER TABLE PUBLIC.GROUPS ALTER COLUMN ID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.USERGROUPS(USERID INTEGER,GROUPID INTEGER,ISDEFAULT BOOLEAN)
CREATE MEMORY TABLE PUBLIC.BIGQUERIES(ID VARCHAR(255) NOT NULL,PROPERTIES VARCHAR(16777216),DESCRIPTION VARCHAR(1024),NAMENODEID VARCHAR(255),DBNAME VARCHAR(255),USERNAME VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.SPREADSHEETQUERYSTATUS(QUERYID VARCHAR(255),NAMENODEID VARCHAR(255),USERNAME VARCHAR(255),CURRENTSTEP VARCHAR(255),STATUS VARCHAR(255),ERROR VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.MAPREDJOBCONFIG(NAMENODEID VARCHAR(255),RMID VARCHAR(255),JOBNAME VARCHAR(255),JARFILE VARCHAR(1024),LIBJARS VARCHAR(10240),FILES VARCHAR(10240),CLASSNAME VARCHAR(1024),ARGUMENTS VARCHAR(10240))
CREATE MEMORY TABLE PUBLIC.ADHOCJOBCONFIG(NAMENODEID VARCHAR(255),RMID VARCHAR(255),JOBNAME VARCHAR(255),JARFILE VARCHAR(1024),LIBJARS VARCHAR(10240),FILES VARCHAR(10240),CLASSNAME VARCHAR(1024),SOURCEPATH VARCHAR(1024),PATHPATTERN VARCHAR(1024),ARGUMENTS VARCHAR(10240))
CREATE MEMORY TABLE PUBLIC.JOBMAPPING(TABLENAME VARCHAR(255),JOBNAME VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.NAMENODE_CUSTOMDB_MAPPING(NAMENODEID VARCHAR(255),DBNAME VARCHAR(255),ANALYTICSDBNAME VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.QUERYEXECUTION(EXECUTIONID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,QUERYID VARCHAR(255),APPLICATIONID VARCHAR(255),STATUS VARCHAR(63),PATH VARCHAR(10240),NAMENODEID VARCHAR(255),USERNAME VARCHAR(255))
ALTER TABLE PUBLIC.QUERYEXECUTION ALTER COLUMN EXECUTIONID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.SPREADSHEETS(SHEETID VARCHAR(255) NOT NULL,PATH VARCHAR(10240),NAMENODEID VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.TAGPARSERS(TAGPARSERID BIGINT GENERATED BY DEFAULT AS IDENTITY(START WITH 1) NOT NULL PRIMARY KEY,TAGPARSERNAME VARCHAR(128),TAGPARSERDESCRIPTION VARCHAR(1024),TAGPARSERLIB VARCHAR(1024),FILETYPE VARCHAR(512),CLASSNAME VARCHAR(256),NAMENODEID VARCHAR(255),ONINGEST BOOLEAN,ISACTIVE BOOLEAN)
ALTER TABLE PUBLIC.TAGPARSERS ALTER COLUMN TAGPARSERID RESTART WITH 1
CREATE MEMORY TABLE PUBLIC.DECOMMISSIONNODES(ID VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.DBMIGRATIONSTATUS(SOURCEDBNAME VARCHAR(255),DESTINATIONDBNAME VARCHAR(255),STARTTIME TIMESTAMP,ENDTIME TIMESTAMP,STATUS VARCHAR(125),PROGRESS VARCHAR(4096),ERROR VARCHAR(4096))
CREATE MEMORY TABLE PUBLIC.NNDBMIGRATIONSTATUS(MIGRATIONID VARCHAR(120) NOT NULL PRIMARY KEY,NAMENODEID VARCHAR(255),HOSTID INTEGER,DESTPATH VARCHAR(10240),DESTDBNAME VARCHAR(255),START_TIME TIMESTAMP NOT NULL,END_TIME TIMESTAMP,STATUS VARCHAR(125),ERROR VARCHAR(4096))
CREATE MEMORY TABLE PUBLIC.NNRESTORESTATUS(RESTOREID VARCHAR(120) NOT NULL PRIMARY KEY,MIGRATIONID VARCHAR(120),NAMENODEID VARCHAR(255),START_TIME TIMESTAMP NOT NULL,END_TIME TIMESTAMP,STATUS VARCHAR(125))
CREATE MEMORY TABLE PUBLIC.NNDBDIAGNOSISSTATUS(DIAGNOSISID VARCHAR(120) NOT NULL PRIMARY KEY,NAMENODEID VARCHAR(255),START_TIME TIMESTAMP NOT NULL,END_TIME TIMESTAMP,STATUS VARCHAR(125),ERROR VARCHAR(4096),ISREPAIR BOOLEAN NOT NULL)
CREATE MEMORY TABLE PUBLIC.ADHOCQUERY(ADHOCID VARCHAR(120) NOT NULL PRIMARY KEY,NAMENODEID VARCHAR(255),RMID VARCHAR(255),SOURCEPATH VARCHAR(255),PARSERECURSIVE BOOLEAN,TYPE VARCHAR(120),ADHOCTABLENAME VARCHAR(255),FILEPATHPATTERN VARCHAR(255),FIELDS VARCHAR(16777216),ENCODING VARCHAR(255),ARGUMENTS VARCHAR(16777216))
CREATE MEMORY TABLE PUBLIC.S3_DATASOURCE(ID VARCHAR(120) NOT NULL,ACCESSKEY VARCHAR(255),SECRETACCESSKEY VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.FTP_DATASOURCE(ID VARCHAR(120) NOT NULL,HOST VARCHAR(255),PORT INTEGER,USERNAME VARCHAR(255),PASSWORD VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.HTTP_DATASOURCE(ID VARCHAR(120) NOT NULL,BASEURL VARCHAR(255),USERNAME VARCHAR(255),PASSWORD VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.EMAIL_DATASOURCE(ID VARCHAR(120) NOT NULL,EMAILADDRESS VARCHAR(255),PASSWORD VARCHAR(255),MAILSERVERADDRESS VARCHAR(255),ACCOUNTNAME VARCHAR(255),PROTOCOL VARCHAR(255),SOCKET VARCHAR(255),PORT INTEGER,CONNECTIONTIMEOUT BIGINT,READTIMEOUT BIGINT)
CREATE MEMORY TABLE PUBLIC.HDFS_DATASOURCE(ID VARCHAR(120) NOT NULL,HOST VARCHAR(255),PORT INTEGER,GROUPNAME VARCHAR(255),USERNAME VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.SSH_DATASOURCE(ID VARCHAR(120) NOT NULL,HOST VARCHAR(255),PORT INTEGER,USERNAME VARCHAR(225),PASSWORD VARCHAR(225),KEY VARCHAR(225))
CREATE MEMORY TABLE PUBLIC.SFTP_DATASOURCE(ID VARCHAR(120) NOT NULL,HOST VARCHAR(255),PORT INTEGER,USERNAME VARCHAR(255),PASSWORD VARCHAR(255))
CREATE MEMORY TABLE PUBLIC.DATA_CONNECTIONS(ID VARCHAR(120) NOT NULL PRIMARY KEY,DATA_CONNECTION_TYPE SMALLINT NOT NULL)
CREATE MEMORY TABLE PUBLIC.CHARTPREFERENCES(PROPERTIES VARCHAR(16777216))
CREATE MEMORY TABLE PUBLIC.CUSTOMTAG_METADATA(ID VARCHAR(255) NOT NULL PRIMARY KEY,JSON VARCHAR(16777216),DESCRIPTION VARCHAR(1024),ISACTIVE BOOLEAN,DB_TYPE VARCHAR(255),FILE_TYPE VARCHAR(255),NAMENODEID VARCHAR(255),TABLE_NAME VARCHAR(255),SCHEDULE_INFO VARCHAR(16777216),JOB_NAMES VARCHAR(16777216))
ALTER TABLE PUBLIC.DATABASE_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_DATABASEFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.S3_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_S3FK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.FTP_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_FTPFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.HTTP_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_HTTPFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.EMAIL_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_EMAILFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.HDFS_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_HDFSFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.SSH_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_SSHFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER TABLE PUBLIC.SFTP_DATASOURCE ADD CONSTRAINT DATA_CONNECTIONS_SFTPFK FOREIGN KEY(ID) REFERENCES PUBLIC.DATA_CONNECTIONS(ID) ON DELETE CASCADE
ALTER SEQUENCE SYSTEM_LOBS.LOB_ID RESTART WITH 1
SET DATABASE DEFAULT INITIAL SCHEMA PUBLIC
GRANT USAGE ON DOMAIN INFORMATION_SCHEMA.SQL_IDENTIFIER TO PUBLIC
GRANT USAGE ON DOMAIN INFORMATION_SCHEMA.YES_OR_NO TO PUBLIC
GRANT USAGE ON DOMAIN INFORMATION_SCHEMA.TIME_STAMP TO PUBLIC
GRANT USAGE ON DOMAIN INFORMATION_SCHEMA.CARDINAL_NUMBER TO PUBLIC
GRANT USAGE ON DOMAIN INFORMATION_SCHEMA.CHARACTER_DATA TO PUBLIC
GRANT DBA TO SA
GRANT DBA TO $SysDBUser$
SET SCHEMA SYSTEM_LOBS
INSERT INTO BLOCKS VALUES(0,2147483647,0)
SET SCHEMA PUBLIC
INSERT INTO HOST_SYSTEM_ATTRIBUTES VALUES('ProcessCpuTime','java.lang:type=OperatingSystem','CPUUSAGE','CPU Usage','FLOAT','CPU Usage')
INSERT INTO HOST_SYSTEM_ATTRIBUTES VALUES('NWBytesReadPerSec','Network','NWRECDBYTESPERSEC','Bytes Rcvd/sec','FLOAT','Network')
INSERT INTO HOST_SYSTEM_ATTRIBUTES VALUES('NWBytesWrittenPerSec','Network','NWSENTBYTESPERSEC','Bytes Sent/sec','FLOAT','Network')
INSERT INTO HOST_SYSTEM_ATTRIBUTES VALUES('DiskBytesReadPerSec','Disk','DSKBYTEREADSPERSEC','Bytes Read/sec','FLOAT','Disk')
INSERT INTO HOST_SYSTEM_ATTRIBUTES VALUES('DiskBytesWrittenPerSec','Disk','DSKBYTEWRITESPERSEC','Bytes Written/sec','FLOAT','Disk')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('ProcessCpuTime','java.lang:type=OperatingSystem','CPUUSAGE','CPU Usage','FLOAT')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('FreePhysicalMemorySize','java.lang:type=OperatingSystem','RAMFREE','Free Physical Memory','FLOAT')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('TotalPhysicalMemorySize','java.lang:type=OperatingSystem','RAMTOTAL','Total Physical Memory','FLOAT')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('NWBytesReadPerSec','Network','NWRECDBYTESPERSEC','Bytes Rcvd/sec','FLOAT')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('NWBytesWrittenPerSec','Network','NWSENTBYTESPERSEC','Bytes Sent/sec','FLOAT')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('DiskBytesReadPerSec','Disk','DSKBYTEREADSPERSEC','Bytes Read/sec','FLOAT')
INSERT INTO HOST_LIVE_ATTRIBUTES VALUES('DiskBytesWrittenPerSec','Disk','DSKBYTEWRITESPERSEC','Bytes Written/sec','FLOAT')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('AddBlockOps','Hadoop:name=NameNodeActivity,service=NameNode','ADDBLOCKOPS','Add Block','BIGINT','Block Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('CreateFileOps','Hadoop:name=NameNodeActivity,service=NameNode','CREATEFILEOPS','Create File','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('DeleteFileOps','Hadoop:name=NameNodeActivity,service=NameNode','DELETEFILEOPS','Delete File','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('FilesAppended','Hadoop:name=NameNodeActivity,service=NameNode','FILESAPPENDED','Append File','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('FilesRenamed','Hadoop:name=NameNodeActivity,service=NameNode','FILESRENAMED','Rename File','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('GetListingOps','Hadoop:name=NameNodeActivity,service=NameNode','LISTOPS','List File','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('FileInfoOps','Hadoop:name=NameNodeActivity,service=NameNode','TOTALFILESREAD','Total Files Read','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('FilesCreated','Hadoop:name=NameNodeActivity,service=NameNode','TOTALFILESWRITE','Total Files Written','BIGINT','File Operations')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('MemHeapCommittedM','Hadoop:name=JvmMetrics,service=NameNode','MEMHEAPCOMMITTEDM','Committed (MB)','FLOAT','Heap Memory')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=NameNode','MEMHEAPUSEDM','Used (MB)','FLOAT','Heap Memory')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('MemNonHeapCommittedM','Hadoop:name=JvmMetrics,service=NameNode','MEMNONHEAPCOMMITTEDM','Committed (MB)','FLOAT','Non Heap Memory')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('MemNonHeapUsedM','Hadoop:name=JvmMetrics,service=NameNode','MEMNONHEAPUSEDM','Used (MB)','FLOAT','Non Heap Memory')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('ThreadsRunnable','Hadoop:name=JvmMetrics,service=NameNode','THREADSRUNNABLE','Runnable','BIGINT','Threads')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('ThreadsBlocked','Hadoop:name=JvmMetrics,service=NameNode','THREADSBLOCKED','Blocked','BIGINT','Threads')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('ThreadsWaiting','Hadoop:name=JvmMetrics,service=NameNode','THREADSWAITING','Waiting','BIGINT','Threads')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('ThreadsTimedWaiting','Hadoop:name=JvmMetrics,service=NameNode','THREADSTIMEDWAITING','Timed Waiting','BIGINT','Threads')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('ThreadsTerminated','Hadoop:name=JvmMetrics,service=NameNode','THREADSTERMINATED','Terminated','BIGINT','Threads')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('ThreadsNew','Hadoop:name=JvmMetrics,service=NameNode','THREADSNEW','New','BIGINT','Threads')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=NameNode','GCCOUNT','Total','BIGINT','GC Count')
INSERT INTO NAMENODE_SYSTEM_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=NameNode','GCTIMEMILLIS','Total (ms)','BIGINT','GC Time')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BlocksWritten','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSWRITTEN','Written','BIGINT','Block Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BlocksRead','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSREAD','Read','BIGINT','Block Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BlocksReplicated','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSREPLICATED','Replicated','BIGINT','Block Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BlocksRemoved','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSREMOVED','Removed','BIGINT','Block Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BlocksVerified','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSVERIFIED','Verified','BIGINT','Block Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BytesWritten','Hadoop:name=DataNodeActivity,service=DataNode','BYTESWRITTEN','Written','BIGINT','Byte Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('BytesRead','Hadoop:name=DataNodeActivity,service=DataNode','BYTESREAD','Read','BIGINT','Byte Operations')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('Remaining','Hadoop:name=FSDatasetState,service=DataNode','REMAINING','Remaining (GB)','FLOAT','Storage')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('DfsUsed','Hadoop:name=FSDatasetState,service=DataNode','DFSUSED','Used (GB)','FLOAT','Storage')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('MemHeapCommittedM','Hadoop:name=JvmMetrics,service=DataNode','MEMHEAPCOMMITTEDM','Committed (MB)','FLOAT','Heap Memory')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=DataNode','MEMHEAPUSEDM','Used (MB)','FLOAT','Heap Memory')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('MemNonHeapCommittedM','Hadoop:name=JvmMetrics,service=DataNode','MEMNONHEAPCOMMITTEDM','Committed (MB)','FLOAT','Non Heap Memory')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('MemNonHeapUsedM','Hadoop:name=JvmMetrics,service=DataNode','MEMNONHEAPUSEDM','Used (MB)','FLOAT','Non Heap Memory')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('ThreadsNew','Hadoop:name=JvmMetrics,service=DataNode','THREADSNEW','New','BIGINT','Threads')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('ThreadsRunnable','Hadoop:name=JvmMetrics,service=DataNode','THREADSRUNNABLE','Runnable','BIGINT','Threads')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('ThreadsBlocked','Hadoop:name=JvmMetrics,service=DataNode','THREADSBLOCKED','Blocked','BIGINT','Threads')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('ThreadsWaiting','Hadoop:name=JvmMetrics,service=DataNode','THREADSWAITING','Waiting','BIGINT','Threads')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('ThreadsTimedWaiting','Hadoop:name=JvmMetrics,service=DataNode','THREADSTIMEDWAITING','Timed Waiting','BIGINT','Threads')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('ThreadsTerminated','Hadoop:name=JvmMetrics,service=DataNode','THREADSTERMINATED','Terminated','BIGINT','Threads')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=DataNode','GCCOUNT','Total','BIGINT','GC Count')
INSERT INTO DATANODE_SYSTEM_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=DataNode','GCTIMEMILLIS','Total (ms)','BIGINT','GC Time')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=NameNode','GCCOUNT','Total','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=NameNode','GCTIMEMILLIS','Total (ms)','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('AddBlockOps','Hadoop:name=NameNodeActivity,service=NameNode','ADDBLOCKOPS','Add Block','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('DeleteFileOps','Hadoop:name=NameNodeActivity,service=NameNode','DELETEFILEOPS','Delete File','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('GetListingOps','Hadoop:name=NameNodeActivity,service=NameNode','LISTOPS','List File','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('TotalBlocks','Hadoop:name=NameNodeInfo,service=NameNode','TOTALBLOCKS','Total Blocks','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('TotalFiles','Hadoop:name=NameNodeInfo,service=NameNode','TOTALFILES','Total Files and Directories','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('CapacityTotalGB','Hadoop:name=FSNamesystem,service=NameNode','CAPACITYTOTALGB','Total Capacity (GB)','FLOAT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('CapacityUsedGB','Hadoop:name=FSNamesystem,service=NameNode','CAPACITYUSEDGB','Used Capacity (GB)','FLOAT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('CapacityRemainingGB','Hadoop:name=FSNamesystem,service=NameNode','CAPACITYREMAININGGB','Used Capacity (GB)','FLOAT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=NameNode','JVMHEAPUSED','JVM Heap','FLOAT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('FileInfoOps','Hadoop:name=NameNodeActivity,service=NameNode','TOTALFILESREAD','Total Files Read','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('FilesCreated','Hadoop:name=NameNodeActivity,service=NameNode','TOTALFILESWRITE','Total Files Written','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('FilesAppended','Hadoop:name=NameNodeActivity,service=NameNode','TOTALFILESAPPENDED','Total Files Appended','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('FilesRenamed','Hadoop:name=NameNodeActivity,service=NameNode','TOTALFILESRENAMED','Total Files Renamed','BIGINT')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('Safemode','Hadoop:name=NameNodeInfo,service=NameNode','SAFEMODESTATUS','Safe Mode Status','VARCHAR(255)')
INSERT INTO NAMENODE_LIVE_ATTRIBUTES VALUES('StartTime','java.lang:type=Runtime','JVMSTARTEDON','JVM Started On','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BlocksReplicated','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSREPLICATED','Replicated','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BlocksRemoved','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSREMOVED','Removed','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BlocksVerified','Hadoop:name=DataNodeActivity,service=DataNode','BLOCKSVERIFIED','Verified','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('VolumeInfo','Hadoop:name=DataNodeInfo,service=DataNode','VOLUMEINFO','Volume Info','VARCHAR(5000)')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BytesRead','Hadoop:name=DataNodeActivity,service=DataNode','BYTESREAD','Total Bytes Read','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BytesWritten','Hadoop:name=DataNodeActivity,service=DataNode','BYTESWRITTEN','Total Bytes Written','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=DataNode','JVMHEAPUSED','JVM Heap','FLOAT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BlocksRead','Hadoop:name=DataNodeActivity,service=DataNode','TOTALBLOCKSREAD','Blocks Read','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('BlocksWritten','Hadoop:name=DataNodeActivity,service=DataNode','TOTALBLOCKSWRITE','Total Blocks Written','BIGINT')
INSERT INTO DATANODE_LIVE_ATTRIBUTES VALUES('StartTime','java.lang:type=Runtime','JVMSTARTEDON','JVM Started On','BIGINT')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersLaunched','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSLAUNCHED','Launched','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersCompleted','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSCOMPLETED','Completed','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersFailed','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSFAILED','Failed','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersKilled','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSKILLED','Killed','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersIniting','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSINITING','Initing','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersRunning','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSRUNNING','Running','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AllocatedContainers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ALLOCATEDCONTAINERS','Allocated','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('PendingContainers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','PENDINGCONTAINERS','Pending','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ReservedContainers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','RESERVEDCONTAINERS','Reserved','INTEGER','Containers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AppsSubmitted','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSSUBMITTED','Submitted','INTEGER','Apps')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AppsRunning','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSRUNNING','Running','INTEGER','Apps')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AppsPending','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSPENDING','Pending','INTEGER','Apps')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AppsCompleted','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSCOMPLETED','Completed','INTEGER','Apps')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AppsKilled','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSKILLED','Killed','INTEGER','Apps')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ActiveApplications','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ACTIVEAPPLICATIONS','Active','INTEGER','Apps')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('NumActiveNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMACTIVENMS','Active','FLOAT','Node Managers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('NumDecommissionedNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMDECOMMISSIONEDNMS','Decommissioned','FLOAT','Node Managers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('NumLostNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMLOSTNMS','Lost','FLOAT','Node Managers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('NumUnhealthyNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMUNHEALTHYNMS','Unhealthy','FLOAT','Node Managers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('NumRebootedNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMREBOOTEDNMS','Rebooted','FLOAT','Node Managers')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ActiveUsers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ACTIVEUSERS','Active','INTEGER','Users')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AllocatedMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ALLOCATEDMB','Allocated','INTEGER','Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('AvailableMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','AVAILABLEMB','Available','INTEGER','Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('PendingMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','PENDINGMB','Pending','INTEGER','Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ReservedMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','RESERVEDMB','Reserved','INTEGER','Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsRunnable','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSRUNNABLE','Runnable','INTEGER','Threads')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsBlocked','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSBLOCKED','Blocked','INTEGER','Threads')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsWaiting','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSWAITING','Waiting','INTEGER','Threads')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsTimedWaiting','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSTIMEDWAITING','Timed Waiting','INTEGER','Threads')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsTerminated','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSTERMINATED','Terminated','INTEGER','Threads')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemHeapCommittedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMHEAPCOMMITTEDM','Committed (MB)','FLOAT','Heap Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMHEAPUSEDM','Used (MB)','FLOAT','Heap Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemNonHeapCommittedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMNONHEAPCOMMITTEDM','Committed (MB)','FLOAT','Non Heap Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemNonHeapUsedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMNONHEAPUSEDM','Used (MB)','FLOAT','Non Heap Memory')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=ResourceManager','GCCOUNT','Count','BIGINT','GC Count')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=ResourceManager','GCTIMEMILLIS','Time(ms)','BIGINT','GC Time')
INSERT INTO RESOURCE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsNew','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSNEW','New','INTEGER','Threads')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('NumActiveNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMACTIVENMS','Active','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('NumDecommissionedNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMDECOMMISSIONEDNMS','Decommissioned','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('NumLostNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMLOSTNMS','Lost','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('NumUnhealthyNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMUNHEALTHYNMS','Unhealthy','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('NumRebootedNMs','Hadoop:name=ClusterMetrics,service=ResourceManager','NUMREBOOTEDNMS','Rebooted','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('MemNonHeapUsedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMNONHEAPUSEDM','MemNonHeapUsedM','FLOAT')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('MemNonHeapCommittedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMNONHEAPCOMMITTEDM','MemNonHeapCommittedM','FLOAT')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMHEAPUSEDM','MemHeapUsedM','FLOAT')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('MemHeapCommittedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMHEAPCOMMITTEDM','MemHeapCommittedM','FLOAT')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=ResourceManager','GCCOUNT','Count','BIGINT')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=ResourceManager','GCTIMEMILLIS','Time(ms)','BIGINT')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsNew','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSNEW','New','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsRunnable','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSRUNNABLE','Runnable','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsBlocked','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSBLOCKED','Blocked','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsWaiting','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSWAITING','Waiting','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsTimedWaiting','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSTIMEDWAITING','Timed Waiting','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsTerminated','Hadoop:name=JvmMetrics,service=ResourceManager','THREADSTERMINATED','Terminated','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersLaunched','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSLAUNCHED','Launched','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersCompleted','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSCOMPLETED','Completed','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersFailed','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSFAILED','Failed','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersKilled','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSKILLED','Killed','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersIniting','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSINITING','Initing','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersRunning','Hadoop:name=QueueMetrics,service=ResourceManager','CONTAINERSRUNNING','Running','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AppsSubmitted','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSSUBMITTED','Submitted','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AppsRunning','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSRUNNING','Running','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AppsPending','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSPENDING','Pending','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AppsCompleted','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSCOMPLETED','Completed','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AppsKilled','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','APPSKILLED','Killed','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ActiveApplications','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ACTIVEAPPLICATIONS','Running','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AllocatedMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ALLOCATEDMB','Allocated','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AvailableMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','AVAILABLEMB','Available','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('PendingMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','PENDINGMB','Pending','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ReservedMB','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','RESERVEDMB','Reserved','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AllocatedContainers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ALLOCATEDCONTAINERS','Allocated','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AggregateContainersAllocated','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','AGGREGATECONTAINERSALLOCATED','Aggregate Allocated','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('AggregateContainersReleased','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','AGGREGATECONTAINERSRELEASED','Aggregate Released','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('PendingContainers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','PENDINGCONTAINERS','Pending','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ReservedContainers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','RESERVEDCONTAINERS','Reserved','INTEGER')
INSERT INTO RESOURCE_MANAGER_LIVE_ATTRIBUTES VALUES('ActiveUsers','Hadoop:name=QueueMetrics,q0=root,service=ResourceManager','ACTIVEUSERS','Active','INTEGER')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersLaunched','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSLAUNCHED','Launched','INTEGER','Containers')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersCompleted','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSCOMPLETED','Completed','INTEGER','Containers')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersFailed','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSFAILED','Failed','INTEGER','Containers')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersKilled','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSKILLED','Killed','INTEGER','Containers')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersIniting','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSINITING','Initing','INTEGER','Containers')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ContainersRunning','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSRUNNING','Running','INTEGER','Containers')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemHeapCommittedM','Hadoop:name=JvmMetrics,service=NodeManager','MEMHEAPCOMMITTEDM','Committed (MB)','FLOAT','Heap Memory')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=NodeManager','MEMHEAPUSEDM','Used (MB)','FLOAT','Heap Memory')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemNonHeapCommittedM','Hadoop:name=JvmMetrics,service=NodeManager','MEMNONHEAPCOMMITTEDM','Committed (MB)','FLOAT','Non Heap Memory')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('MemNonHeapUsedM','Hadoop:name=JvmMetrics,service=NodeManager','MEMNONHEAPUSEDM','Used (MB)','FLOAT','Non Heap Memory')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsNew','Hadoop:name=JvmMetrics,service=NodeManager','THREADSNEW','New','INTEGER','Threads')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsRunnable','Hadoop:name=JvmMetrics,service=NodeManager','THREADSRUNNABLE','Runnable','INTEGER','Threads')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsBlocked','Hadoop:name=JvmMetrics,service=NodeManager','THREADSBLOCKED','Blocked','INTEGER','Threads')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsWaiting','Hadoop:name=JvmMetrics,service=NodeManager','THREADSWAITING','Waiting','INTEGER','Threads')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsTimedWaiting','Hadoop:name=JvmMetrics,service=NodeManager','THREADSTIMEDWAITING','Timed Waiting','INTEGER','Threads')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('ThreadsTerminated','Hadoop:name=JvmMetrics,service=NodeManager','THREADSTERMINATED','Terminated','INTEGER','Threads')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=NodeManager','GCCOUNT','Count','BIGINT','GC Count')
INSERT INTO NODE_MANAGER_SYSTEM_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=NodeManager','GCTIMEMILLIS','Time(ms)','BIGINT','GC Time')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersLaunched','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSLAUNCHED','Launched','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersCompleted','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSCOMPLETED','Completed','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersFailed','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSFAILED','Failed','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersKilled','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSKILLED','Killed','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersIniting','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSINITING','Initing','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ContainersRunning','Hadoop:name=NodeManagerMetrics,service=NodeManager','CONTAINERSRUNNING','Running','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('MemHeapCommittedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMHEAPCOMMITTEDM','Committed (MB)','FLOAT')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('MemHeapUsedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMHEAPUSEDM','Used (MB)','FLOAT')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('MemNonHeapCommittedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMNONHEAPCOMMITTEDM','Committed (MB)','FLOAT')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('MemNonHeapUsedM','Hadoop:name=JvmMetrics,service=ResourceManager','MEMNONHEAPUSEDM','Used (MB)','FLOAT')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsNew','Hadoop:name=JvmMetrics,service=NodeManager','THREADSNEW','New','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsRunnable','Hadoop:name=JvmMetrics,service=NodeManager','THREADSRUNNABLE','Runnable','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsBlocked','Hadoop:name=JvmMetrics,service=NodeManager','THREADSBLOCKED','Blocked','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsWaiting','Hadoop:name=JvmMetrics,service=NodeManager','THREADSWAITING','Waiting','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsTimedWaiting','Hadoop:name=JvmMetrics,service=NodeManager','THREADSTIMEDWAITING','Timed Waiting','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('ThreadsTerminated','Hadoop:name=JvmMetrics,service=NodeManager','THREADSTERMINATED','Terminated','INTEGER')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('GcCount','Hadoop:name=JvmMetrics,service=NodeManager','GCCOUNT','Count','BIGINT')
INSERT INTO NODE_MANAGER_LIVE_ATTRIBUTES VALUES('GcTimeMillis','Hadoop:name=JvmMetrics,service=NodeManager','GCTIMEMILLIS','Time(ms)','BIGINT')
INSERT INTO BILLING_CONFIG_DATA VALUES(0,0,0,0,0,0,0)
INSERT INTO HADOOPCONFIG VALUES('Common','queryio.bigquery.db.insert-statement','CREATE TABLE','QueryIO custom tag default create table statement.')
INSERT INTO HADOOPCONFIG VALUES('Common','queryio.bigquery.db.dbconfig-path','','dbconfig.xml file path to initialize database pool.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','dfs.replication','1','Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','dfs.replication.min','1','Minimal block replication.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','dfs.heartbeat.interval','3','Determines datanode heartbeat interval in seconds.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','dfs.namenode.heartbeat.recheck-interval','300000','Determines datanode heartbeat recheck interval in milliseconds.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','fs.checkpoint.period','3600','The number of seconds between two periodic checkpoints.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','dfs.datanode.scan.period.hours','0','Interval in hours for Datanode to scan data directories and reconcile the difference between blocks in memory and on the disk. If set to 0, the interval defaults to 3 weeks')
INSERT INTO HADOOPCONFIG VALUES('High Availability','dfs.blockreport.intervalMsec','21600000','Determines block reporting interval in milliseconds.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','queryio.agent.monitor.interval','10','Agent monitor interval in minutes.')
INSERT INTO HADOOPCONFIG VALUES('High Availability','queryio.node.monitor.interval','60','Node monitor interval in seconds.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.blocksize','67108864','The default block size for new HDFS files.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.nameservices','','Comma-separated list of nameservices.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.ha.namenodes','','The prefix for a given nameservice, contains a comma-separated list of namenodes for a given nameservice (eg EXAMPLENAMESERVICE).')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.ha.namenode.id',' ','The ID of this namenode. If the namenode ID is not configured it is determined automatically by matching the local node''s address with the configured address.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.replication.max','512','Maximal block replication.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.permissions.enabled','true','If "true", enable permission checking in HDFS. If "false", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.permissions.superusergroup','queryio','The name of the group of super-users.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.namenode.upgrade.permission','777','The name of the group of super-users.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','hadoop.security.groups.cache.secs','30','User Group Information cache refresh interval in seconds.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.https.enable','false','Decide if HTTPS(SSL) is supported on HDFS.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.https.port','50470','The namenode secure http port.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.https.server.keystore.resource','ssl-server.xml','Resource file from which ssl server keystore information will be extracted.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.client.https.keystore.resource','ssl-client.xml','Resource file from which ssl client keystore information will be extracted.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.client.https.need-auth','false','Whether SSL client certificate authentication is required.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.client.block.write.retries','3','The number of retries for writing blocks to the data nodes, before we signal failure to the application.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','dfs.webhdfs.enabled','true','Enable WebHDFS (REST API) in Namenodes and Datanodes.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','io.file.buffer.size','16384','The size of buffer for use in sequence files. The size of this buffer should probably be a multiple of hardware page size (4096 on Intel x86), and it determines how much data is buffered during read and write operations.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','io.bytes.per.checksum','512','The number of bytes per checksum. Must not be larger than dfs.stream-buffer-size.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','fs.trash.interval','0','Number of minutes between trash checkpoints. To disable the trash feature, enter 0.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','fs.df.interval','600000','Disk usage statistics refresh interval in milliseconds.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','hadoop.security.authorization','true','Is service-level authorization enabled?')
INSERT INTO HADOOPCONFIG VALUES('HDFS','hadoop.security.group.mapping','com.queryio.plugin.groupinfo.QueryIOGroupInfoServiceProvider','Class for user to group mapping (get groups for a given user) for ACL')
INSERT INTO HADOOPCONFIG VALUES('HDFS','queryio.controller.data.fetch.interval','15','Data fetch interval in seconds')
INSERT INTO HADOOPCONFIG VALUES('HDFS','queryio.hadoop.options','-server -Xmn400M -XX:PermSize=128M -XX:MaxPermSize=256m -XX:+UnlockExperimentalVMOptions -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseStringCache -XX:+AggressiveOpts -XX:+EliminateLocks -XX:+UseBiasedLocking -XX:+ExplicitGCInvokesConcurrent -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Dfile.encoding=UTF-8','Extra Java runtime options options. Used by queryio server for hadoop runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','queryio.hadoop.log-dir','','Where log files are stored. Used by queryio server for hadoop runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','queryio.hadoop.pid-dir','','The directory where pid files are stored. Used by queryio server for hadoop runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('HDFS','queryio.hadoop.heap-size','4096','The maximum amount of heap to use, in MB. Used by queryio server for hadoop runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.du.reserved','0','Reserved space in bytes per volume. Always leave this much space free for non dfs use.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.handler.count','10','The number of server threads for the datanode.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.address','0.0.0.0:50010','The address where the datanode server will listen to. If the port is 0 then the server will start on a free port.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.http.address','0.0.0.0:50075','The datanode http server address and port. If the port is 0 then the server will start on a free port.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.ipc.address','0.0.0.0:50020','The datanode ipc server address and port. If the port is 0 then the server will start on a free port.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.https.address','0.0.0.0:50475','The datanode secure http server address and port.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.max.transfer.threads','4096','Specifies the maximum number of threads to use for transferring data in and out of the DN.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.data.dir.perm','700','Permissions for the directories on on the local filesystem where the DFS data node store its blocks. The permissions can either be octal or symbolic.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','dfs.datanode.data.dir','file://${hadoop.tmp.dir}/dfs/data','Determines where on the local filesystem the DFS data node should store the data. If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','queryio.datanode.data.disk','','Datanode directory''s disk name for monitoring.')
INSERT INTO HADOOPCONFIG VALUES('Datanode','queryio.datanode.options','-Dcom.sun.management.jmxremote $HADOOP_DATANODE_OPTS -Dcom.sun.management.jmxremote.port=9006 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl.need.client.auth=false -Dcom.sun.management.jmxremote.ssl=false','Datanode specific runtime options. Used by queryio server for hadoop runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','fs.permissions.umask-mode','022','Default permission for file/folder.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.umaskmode','022','Default permission for file/folder.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.client.failover.proxy.provider.mycluster','org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider','The Java class that HDFS clients use to contact the Active NameNode')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.ha.fencing.methods','sshfence','A list of scripts or Java classes which will be used to fence the Active NameNode during a failover.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.ha.fencing.ssh.private-key-files','/root/.ssh/id_rsa','A comma-separated list of SSH private key files.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.name.dir','file://${hadoop.tmp.dir}/dfs/name','Determines where on the local filesystem the DFS name node should store the name table(fsimage). If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.shared.edits.dir','','A directory on shared storage between the multiple namenodes in an HA cluster. This directory will be written by the active and read by the standby in order to keep the namespaces synchronized. This directory does not need to be listed in dfs.namenode.edits.dir. It should be left empty in a non-HA cluster.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.hosts','','Names a file that contains a list of hosts that are permitted to connect to the namenode. The full pathname of the file must be specified. If the value is empty, all hosts are permitted.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.hosts.exclude','','Names a file that contains a list of hosts that are not permitted to connect to the namenode. The full pathname of the file must be specified. If the value is empty, no hosts are excluded.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.http-address','0.0.0.0:50070','The address and the base port where the dfs namenode web ui will listen on. If the port is 0 then the server will start on a free port.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.https-address','0.0.0.0:50470','The namenode secure http server address and port.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.rpc-address','0.0.0.0:9000','The fully-qualified RPC address for each NameNode for a given nameservice to listen on')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.handler.count','100','The number of server threads for the namenode.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.safemode.threshold-pct','0.999f','Specifies the percentage of blocks that should satisfy the minimal replication requirement defined by dfs.namenode.replication.min. Values less than or equal to 0 mean not to wait for any particular percentage of blocks before exiting safemode. Values greater than 1 will make safe mode permanent.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.namenode.safemode.extension','30000','Determines extension of safe mode in milliseconds after the threshold level is reached.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.nameservice.id','','The ID of this nameservice. If the nameservice ID is not configured or more than one nameservice is configured for dfs.federation.nameservices it is determined automatically by matching the local node''s address with the configured address.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','dfs.block.replicator.classname','org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault','HDFS Block Placement policy. Default value : org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','net.topology.script.file.name','','The script name that should be invoked to resolve DNS names to NetworkTopology names. Example: the script would take host.foo.bar as an argument, and return /rack1 as the output.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','net.topology.script.number.args','1','The max number of args that the script configured with net.topology.script.file.name should be run with. Each arg is an IP address.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.namenode.options','-Dcom.sun.management.jmxremote $HADOOP_NAMENODE_OPTS -Dcom.sun.management.jmxremote.port=9004 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl.need.client.auth=false -Dcom.sun.management.jmxremote.ssl=false','Namenode specific runtime options. Used by queryio server for hadoop runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.namenode.data.disk','','Namenode directory''s disk name for monitoring.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.bigquery.db.dbsourceid','','QueryIO custom tag poolname.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.analytics.db.dbsourceid','','QueryIO Analytics db poolname.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.s3server.port','5667','QueryIO S3 Compatible Service port specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.s3server.ssl.port','5668','QueryIO S3 Compatible Service secure-port port specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hdfsoverftp.port','5669','QueryIO HDFS Over FTP Server port specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.ftpserver.port','5660','QueryIO FTP port specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.ftpserver.ssl.enabled','false','QueryIO Secure FTP enabled.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.ftpserver.ssl.port','5670','QueryIO Secure FTP port specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.ftpserver.ssl.keystore','','SSL keystore for QueryIO Secure FTP specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.ftpserver.ssl.password','hadoop','SSL password for QueryIO Secure FTP specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.dfs.data.encryption.key','vdphkLF2eWW4k0h542VX1gKZWaT2JrIY','Server side data encryption key')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.server.url','http://localhost:5678/queryio/','QueryIO Services port specific to node.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','fs.defaultFS','file:///','The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri''s scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri''s authority is used to determine the host, port, etc. for a filesystem.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','yarn.resourcemanager.address','0.0.0.0:8040','The address of the applications manager interface in the RM.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','yarn.resourcemanager.scheduler.address','0.0.0.0:8030','The address of the scheduler interface.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','yarn.resourcemanager.webapp.address','0.0.0.0:8088','The address of the RM web application.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','yarn.resourcemanager.resource-tracker.address','0.0.0.0:8025','The address of the RM Resource Tracker.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','yarn.resourcemanager.admin.address','0.0.0.0:8141','The address of the RM admin interface.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','mapreduce.framework.name','yarn','The runtime framework for executing MapReduce jobs. Can be one of local, classic or yarn.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','mapreduce.map.memory.mb','1536','The amount of memory the MR AppMaster needs.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','mapreduce.reduce.memory.mb','3072','Larger resource limit for reduces.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','mapreduce.task.io.sort.mb','512','The total amount of buffer memory to use while sorting files, in megabytes. By default, gives each merge stream 1MB, which should minimize seeks.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','mapreduce.task.io.sort.factor','100','The number of streams to merge at once while sorting files. This determines the number of open file handles.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','mapreduce.reduce.shuffle.parallelcopies','50','The default number of parallel transfers run by reduce during the copy(shuffle) phase.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','queryio.yarn.options','-server -Dorg.xerial.snappy.lib.name=libsnappyjava.jnilib -Dorg.xerial.snappy.tempdir=/tmp -Xmn400M -XX:PermSize=128M -XX:MaxPermSize=256m -XX:+UnlockExperimentalVMOptions -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseStringCache -XX:+AggressiveOpts -XX:+EliminateLocks -XX:+UseBiasedLocking -XX:+ExplicitGCInvokesConcurrent -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Dfile.encoding=UTF-8','Extra Java runtime options options. Used by queryio server for yarn runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','queryio.yarn.log-dir','','Where log files are stored. Used by queryio server for yarn runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','queryio.yarn.pid-dir','','The directory where pid files are stored. Used by queryio server for yarn runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Map Reduce','queryio.yarn.heap-size','4096','The maximum amount of heap to use, in MB. Used by queryio server for yarn runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.resourcemanager.client.thread-count','10','The number of threads used to handle applications manager requests.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.resourcemanager.scheduler.client.thread-count','10','Number of threads to handle scheduler interface.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.resourcemanager.admin.client.thread-count','1','Number of threads used to handle RM admin interface.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.resourcemanager.resource-tracker.client.thread-count','10','Number of threads to handle resource tracker calls.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.scheduler.minimum-allocation-mb','128','The minimum allocation size for every container request at the RM, in MBs. Memory requests lower than this won''t take effect, and the specified value will get allocated at minimum.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.scheduler.maximum-allocation-mb','10240','The maximum allocation size for every container request at the RM, in MBs. Memory requests higher than this won''t take effect, and will get capped to this value.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','yarn.app.mapreduce.am.resource.mb','1536','The amount of memory the MR AppMaster needs.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','mapred.child.java.opts','-Xmx1024m -Djava.awt.headless=true -Dorg.xerial.snappy.lib.name=libsnappyjava.jnilib -Dorg.xerial.snappy.tempdir=/tmp','Java opts for the task tracker child processes.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','mapreduce.jobhistory.address','0.0.0.0:10020','MapReduce JobHistory Server IPC host:port')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','mapreduce.jobhistory.webapp.address','0.0.0.0:19888','MapReduce JobHistory Server Web UI host:port')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','mapreduce.jobhistory.intermediate-done-dir','/mr-history/tmp','Directory where history files are written by MapReduce jobs.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','mapreduce.jobhistory.done-dir','/mr-history/done','Directory where history files are managed by the MR JobHistory Server.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','queryio.unit.num.splits','100','Number of splits for each mapper.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','queryio.db.batch-size.max','100','Max batch-size of statements to be executed into db.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','queryio.thread-count.max','50','Max no of threads for each mapper to parse splits.')
INSERT INTO HADOOPCONFIG VALUES('Resource Manager','queryio.resourcemanager.options','-Dcom.sun.management.jmxremote $YARN_RESOURCEMANAGER_OPTS -Dcom.sun.management.jmxremote.port=9008 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl.need.client.auth=false -Dcom.sun.management.jmxremote.ssl=false','Resource Manager specific runtime options. Used by queryio server for yarn runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.address','0.0.0.0:0','Address of node manager IPC.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.localizer.address','0.0.0.0:4344','Address where the localizer IPC is.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.container-manager.thread-count','5','Number of threads container manager uses.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.localizer.client.thread-count','5','Number of threads to handle localization requests.\u0009')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.heartbeat.interval-ms','1000','Heartbeat interval to RM')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.local-dirs','/tmp/nm-local-dir','List of directories to store localized files in.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.log-dirs','/tmp/logs','Where to store container logs.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.resource.memory-mb','8192','Amount of physical memory, in MB, that can be allocated for containers.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.webapp.address','0.0.0.0:9999','NM Webapp address.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','yarn.nodemanager.aux-services','mapreduce_shuffle','TShuffle service that needs to be set for Map Reduce applications.')
INSERT INTO HADOOPCONFIG VALUES('Node Manager','queryio.nodemanager.options','-Dcom.sun.management.jmxremote $YARN_NODEMANAGER_OPTS -Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl.need.client.auth=false -Dcom.sun.management.jmxremote.ssl=false','Node Manager specific runtime options. Used by queryio server for yarn runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','dfs.namenode.secondary.http-address','0.0.0.0:50090','The secondary namenode http server address and port. If the port is 0 then the server will start on a free port.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','dfs.namenode.checkpoint.dir','file://${hadoop.tmp.dir}/dfs/namesecondary','Determines where on the local filesystem the DFS secondary name node should store the temporary images to merge. If this is a comma-delimited list of directories then the image is replicated in all of the directories for redundancy.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','dfs.namenode.checkpoint.period','3600','The number of seconds between two periodic checkpoints.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','dfs.namenode.checkpoint.txns','40000','The Secondary NameNode or CheckpointNode will create a checkpoint of the namespace every "dfs.namenode.checkpoint.txns" transactions, regardless of whether "dfs.namenode.checkpoint.period" has expired.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','dfs.namenode.checkpoint.check.period','60','The SecondaryNameNode and CheckpointNode will poll the NameNode every "dfs.namenode.checkpoint.check.period" seconds to query the number of uncheckpointed transactions.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','dfs.namenode.num.checkpoints.retained','2','The number of image checkpoint files that will be retained by the NameNode and Secondary NameNode in their storage directories. All edit logs necessary to recover an up-to-date namespace from the oldest retained checkpoint will also be retained.')
INSERT INTO HADOOPCONFIG VALUES('Checkpoint Node','queryio.secondarynamenode.options','-Dcom.sun.management.jmxremote $HADOOP_SECONDARYNAMENODE_OPTS -Dcom.sun.management.jmxremote.port=9005 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl.need.client.auth=false -Dcom.sun.management.jmxremote.ssl=false','Checkpoint Node specific runtime options. Used by queryio server for hdfs runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Journal Node','dfs.journalnode.rpc-address','0.0.0.0:8485','The JournalNode RPC server address and port.')
INSERT INTO HADOOPCONFIG VALUES('Journal Node','dfs.journalnode.http-address','0.0.0.0:8480','The address and port the JournalNode web UI listens on. If the port is 0 then the server will start on a free port.')
INSERT INTO HADOOPCONFIG VALUES('Journal Node','dfs.journalnode.edits.dir','','The absolute path on the JournalNode machines where the edits and other local state used by the JNs will be stored')
INSERT INTO HADOOPCONFIG VALUES('Journal Node','queryio.journalnode.options','-Dcom.sun.management.jmxremote $HADOOP_JOURNALNODE_OPTS -Dcom.sun.management.jmxremote.port=9007 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl.need.client.auth=false -Dcom.sun.management.jmxremote.ssl=false','Journal Node specific runtime options. Used by queryio server for hdfs runtime configuration.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.connection.driver','org.apache.hive.jdbc.HiveDriver','Connection driver for hive.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.connection.url','jdbc:hive2://0.0.0.0:10000/default','Connection url for hive.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.connection.username','','Connection username for hive.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.connection.password','','Connection password for hive.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.warehouse.dir','file:///tmp/hive','Location of default database for the warehouse.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.template.dir','file:///hiveTemplate/sample','Location of default database for the template.')
INSERT INTO HADOOPCONFIG VALUES('Namenode','queryio.hive.framework.name','local','The runtime framework for hive. Can be one of local or yarn.')
INSERT INTO CHARTPREFERENCES VALUES(NULL)
