<html>
<head>
	<meta http-equiv="Content-Language" content="en-us">
	<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  	<meta http-equiv="Content-style-type" content="text/css">
  	<link rel="stylesheet" href="../../../common/css/stylesheet_ns.css" type="text/css">
  	<title>Getting Started: GET Service</title>
	
</head>
<body>
<h1><span>Get list of directories</span></h1>
<p>GET Service operation is used to fetch the list of all the directories in root directory.</p>

<h2 id="java"><span>DFS Client API</span></h2>
<p>The code given below fetches the list of all the top level buckets in HDFS using DFS client APIs.</p>
<p>Configuration settings consist of URL and replication count for files. Hadoop file system object is used with these configuration settings.
<code>FileSystem.listFiles(org.apache.hadoop.fs.Path)</code> is used to  get all the buckets available. </p>
<div id="code" style="background:EEE;">
	<pre>
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.LocatedFileStatus;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.RemoteIterator;
import org.apache.hadoop.hdfs.DFSConfigKeys;

public class GetService {
	/*
	 * This program lists all the directories in a server non recursively.
	 */
	public static void main(String[] args) throws IOException{
		Configuration conf = new Configuration(true);	//Create a configuration object to define hdfs properties
		conf.set(DFSConfigKeys.FS_DEFAULT_NAME_KEY, "hdfs://192.168.0.1:9000"); // URL for your namenode
		conf.set(DFSConfigKeys.DFS_REPLICATION_KEY, "3"); // Replication count for files you write
		
		FileSystem dfs = FileSystem.get(conf);	//Returns the configured filesystem implementation.
		
		FileStatus[] statusList = dfs.listStatus(new Path("/"));	//get directories from root directory
		for(int i=0; i&lt;statusList.length; i++){
			if(statusList[i].isDir()){
				System.out.println(statusList[i].getPath().getName());	//display directory name
			}
		}
	}
}

	
	</pre>
</div>

<br><hr align="center" class="whs4">
<h4 class="whs5">Copyright © 2015 QueryIO Corporation. All Rights Reserved. </h4>
<h4 class="whs5">QueryIO, "Big Data Intelligence" and the QueryIO Logo are trademarks
of QueryIO Corporation. Apache, Hadoop and HDFS are trademarks of The Apache Software Foundation.</h4>



</body>
</html>