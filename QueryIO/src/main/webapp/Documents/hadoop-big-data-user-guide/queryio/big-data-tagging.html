<html>
	<head>
		<meta content="en-us" http-equiv="Content-Language" />
		<meta content="text/html; charset=iso-8859-1" http-equiv="Content-Type" />
		<meta content="text/css" http-equiv="Content-style-type" />
		<link href="../../common/css/stylesheet_ns.css" rel="stylesheet" type="text/css" />
		<title>Big Data - On Ingest Tagging</title>
	</head>
	<body>
		<h1><span>&nbsp;Description</span></h1>
		<p>QueryIO provides a feature to associate tagging with files. 
		QueryIO allows you to configure a database instance for use with each Namespace. 
		The tags associated to each file are stored in this databases. 
		This enables you to search for specific files as per the tags they've been associated with. 
		You can execute standard SQL queries on the database specifying the filters and retrieve a list of the files that pertain to your need at the moment.
		QueryIO can stores two types of tags for a file:
		<ul>
			<li><a href="#file">File Metadata</a></li>
			<li><a href="#content">Data Tags</a></li>
		</ul>
		</p>
		<h2 id="file"><span>&nbsp;File Metadata</span></h2>
		<p>Metadata (metacontent) is defined as data providing information about one or more aspects of the data.
			Every type of file has some associated properties with it that can help to make it searchable. 
			These properties includes such things as the name of the author or the date that the file was last modified. 
			These could be file specific, such as aspect ratio or dimensions of an image file.</p>
		<h3>
			<span>Core Metadata</span></h3>
		<p>
			The namespace of the entire filesystem, including the mapping of blocks to files and file system properties, is stored in HDFS.
			Core Metadata refers to these properties that are stored in HDFS.
			When you upload any files to QueryIO, it automatically extracts this HDFS metadata for those files from HDFS. 
			The extracted metadata is then stored in the associated table in the database. 
			Using the extracted metadata you can also reconstruct the file system namespace so that you do not loose access to your data even if your Namenode crashes.</p>
		<p>Database schema for storing hdfs metadata is as follows:</p>
		<table border="1" cellspacing="0" width="100%">
			<tbody>
				<tr>
					<th>
						Parameter</th>
					<th>
						Description</th>
					<th>
						Data Type</th>
					<th>
						Column Name</th>
				</tr>
				<tr>
				</tr>
				<tr>
					<td align="center">
						<em><code>File path</code></em></td>
					<td>
						<p>
							Absolute path of the file on the cluster</p>
					</td>
					<td>
						String</td>
					<td>
						FILEPATH</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Access time</code></em></td>
					<td>
						<p>
							The time when the file was last accessed</p>
					</td>
					<td>
						Timestamp</td>
					<td>
						ACCESSTIME</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Modification time</code></em></td>
					<td>
						<p>
							The time when the file was last modified</p>
					</td>
					<td>
						Timestamp</td>
					<td>
						MODIFICATIONTIME</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Owner</code></em></td>
					<td>
						<p>
							Name of the file owner</p>
					</td>
					<td>
						String</td>
					<td>
						OWNER</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>User group</code></em></td>
					<td>
						<p>
							User group to which the file belongs</p>
					</td>
					<td>
						String</td>
					<td>
						USERGROUP</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Permission</code></em></td>
					<td>
						<p>
							Permissions of the file</p>
					</td>
					<td>
						String</td>
					<td>
						PERMISSION</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Block size</code></em></td>
					<td>
						<p>
							Size of the blocks of the file</p>
					</td>
					<td>
						Integer</td>
					<td>
						BLOCKSIZE</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Replication</code></em></td>
					<td>
						<p>
							Replication count for the file</p>
					</td>
					<td>
						Integer</td>
					<td>
						REPLICATION</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Length</code></em></td>
					<td>
						<p>
							Length of the file in bytes</p>
					</td>
					<td>
						Integer</td>
					<td>
						LEN</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Compression Type</code></em></td>
					<td>
						<p>
							Compression algorithm used for the file. Supported algorithms are SNAPPY, GZ, LZ4.</p>
					</td>
					<td>
						String</td>
					<td>
						COMPRESSION_TYPE</td>
				</tr>
				<tr>
					<td align="center">
						<em><code>Encryption Type</code></em></td>
					<td>
						<p>
							Encryption algorithm used for the file. Supported algorithms are AES256</p>
					</td>
					<td>
						String</td>
					<td>
						ENCRYPTION_TYPE</td>
				</tr>
			</tbody>
		</table>

		<h3>
			<span>Extended Metadata</span></h3>
		<p>
			Extended metadata feature of QueryIO enables users to associate files in HDFS with metadata that is not interpreted by the file system, whereas hdfs metadata has a purpose strictly defined by HDFS(such as permissions or records of creation and modification times). Typical usage can be storing the author of a document, the character encoding of a plain-text document, a checksum, or digital signature.</p>
		<p>
			To support Extended Metadata for standard files, QueryIO uses Apache Tika<span style="background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); font-family: arial, sans-serif; font-size: small; line-height: 16px;">&trade;</span> to parse and extract metadata from various files.</p>
		<p>
			Some of the supported document formats are enumerated below:</p>
		<ul>
			<li>
				HyperText Markup Language</li>
			<li>
				XML and derived formats</li>
			<li>
				Microsoft Office document formats</li>
			<li>
				OpenDocument Format</li>
			<li>
				Apple iWorks Formats</li>
			<li>
				Portable Document Format</li>
			<li>
				Electronic Publication Format</li>
			<li>
				Rich Text Format</li>
			<li>
				Compression and packaging formats</li>
			<li>
				Text formats</li>
			<li>
				Audio formats</li>
			<li>
				Image formats</li>
			<li>
				Video formats</li>
			<li>
				Java class files and archives</li>
			<li>
				The mbox format</li>
			<li>
				The DWG (AutoCAD) format</li>
			<li>
				Font formats</li>
			<li>
				Scientific formats</li>
		</ul>
		<p>
			When you upload any file to HDFS using QueryIO, it automatically parses the file and stores the extracted metadata in the associated table (specific to file type) in the database.</p>
		<p>
			For instance, if you upload a PDF file to QueryIO, information like author, subject, number of pages, etc will be extracted from that file. 
			All of this extracted information will be saved in the respective columns in the METADATA_PDF table in the database.
			You can view the schema for such a schema from "Manage Datasource" view. 
			Following is an example showing some of the columns / fields for METADATA_PDF table.</p>
		<img src="images/screenshots/extended-metadata1.png" />
		<p>&nbsp;</p>
		<p>
			You can also register your own metadata parser to support other file formats.</p>
		<p>
			If you do not want QueryIO to extract the metadata from the files during ingestion, you can disable the registered parser from the &quot;Manage DataSources&quot; view.</p>
		<h2 id="content"><span>&nbsp;Data Tags</span></h2>
		<p>
			As you probably know, every file on your system has a set of attributes called file properties that includes such things as the name of the author or the date that the file was last modified. 
			Tags are another type of file property, designed to be customized by the user. 
			Tags are great for making searching easier because you can use words or even phrases that make sense to you. 
			You can think of Tags as keywords.</p>
		<p>
			While tagging is a great feature, Hadoop, which QueryIO is based on does not allow you to tag your files. 
			This leaves you in the dark as you have no way of filtering your files except going through the entire list of files and manually looking for the files you need.</p>
		<p>
			To combat this, QueryIO uses a fusion of contemporary relational databases and Hadoop. 
			The tags for all the files stored in HDFS are stored in the database.</p>
		<p>
			This enables you to tag your files and it makes searching for specific files even easier.</p>
		<p>
			You just need to execute standard SQL queries on the database specifying the filters and you can retreive a list of the files that pertain to your need at the moment.</p>
		<h3>
			<strong>Real World Scenario</strong></h3>
		<p>
			Lets say you have multiple spreadsheets containing prices for individual stocks respectively.</p>
		<p>
			The columns in the file would probably be: DATE, OPEN, HIGH, LOW, CLOSE, VOLUME.</p>
		<p>
			Now, lets say, you want to find those stocks for which the volume on any particular day crossed 100K.</p>
		<p>
			Here are the approaches that you can follow:</p>
		<p>
			1) One approach would be to scan through all those files manually to check for this information. Now that would be very tiresome approach to follow.</p>
		<p>
			2) Alternatively, you can upload those files to HDFS and choose to write a map-reduce job to process all those files and extract the information you need.</p>
		<p>
			Both the above approaches would be extremely cumbersome and costly.</p>
		<p>
			Intelligent data tagging feature of QueryIO keeps all your problems at bay and lets you focus on other important tasks while it takes care of processing all those files to extract all the information you need.</p>
		<h3>
			<strong>Intelligent Data Tagging</strong></h3>
		<p>
			QueryIO has a lot of intelligent content processors which can analyze the content of your files to extract specific information.</p>
		<p>
			You can specify the conditional expressions to tag only those files that meet your condition.</p>
		<p>
			You can also specify arithmetic and logical operations to evaluate on the content of your files. The result of these operations will be saved as a tag to those files which meet the condition that you had specified.</p>
		<p>
			<strong>On Ingest Tagging</strong></p>
		<p>
			The on ingest tagging feature enables QueryIO to process and tag your files while they are still on the way to HDFS. This saves you from the trouble of having to write and execute map-reduce jobs which is pretty much labour intensive.</p>
		<p>
			<strong>Post Ingest Tagging</strong></p>
		<p>
			The post ingest tagging feature executes a typical map-reduce job to explicitly assign tags to the files that already exist on your cluster.</p>
		<p>
			It can be helpful in following scenarios:</p>
		<p>
			1) At any point of time if you choose to alter the tags that you had previously assigned to your files.</p>
		<p>
			2) You did not apply any tags to your files earlier but want to do it now.</p>
		<p>
			To add a data tag, navigate to <b>Data &gt; Data Tagging</b> view.</p>
		<h2 id="add">
			<span>Add Data Tag</span></h2>
		<p> To add a data tag, navigate to <b>Data > Data Tagging</b> view.</p>
	
	
	<p>Following example guides you to add a data tag on a hive table : <b>hivecsvtable1</b> which finds average reading of CPU in a particular file for host 192.168.0.4</p> 

	<ul>
		<li>Click on <b>Add</b> button in the Data Tagging view to define a new Data Tag.</li>
		<li><b>Tag ID</b>: Enter a unique ID for data tag which will be column name in your hive table. [For example : <b>Tag_1</b>]</li>
		<li><b>Tag Description</b>: Provide description for this tag. [Say : <b>Average of CPU for 192.168.0.4</b>]</li>
		<li><b>Select NameNode</b>: Select a namespace under which files will be parsed for tagging.</li>
		<li><b>Select Database</b>: Select a database from Metastore database or Hive database on tables of which tags will be added. For our example, select <b>Hive</b> .</li>
		<li><b>Select Table</b>: Select <b>hivecsvtable1</b> table.</li>
		<li><b>Is Enabled</b>: Check box to enable or disable the data tagging.</li>
		<li>Click on <b>Next</b> to define the operator and conditions.</li>
		<br><img alt="NM-add3" src="images/screenshots/data-tagging1.png" >	<br><br>
		
		<li><b>Tag ID </b> Enter a Tag Id which is the actual Field Name that identifies the Tag in queries.</li>
		<li><b>Operator Type</b>: You can choose the tag value to be</li>
			<ul>
				<li><b>Global Function</b>: Function applied on entire content of the file and resultant value is given to the tag.</li>
				<li><b>Table Column Operator</b>: Operation is performed on a chosen column name from the defined schema and the resultant value is given to the tag (option not available in case no table is chosen).</li>
				<li><b>Constant Value</b>: A single constant value is given to the tag.</li>
			For our example, select the "Table Column Operator" as "avg(CPU)"
			</ul>
			
		<li><b>Conditional Expression</b>: You can provide a compound expression that contains a condition on your data, which when evaluated to true would be included in the computation of Tag Value. Now to tag only those entries where IP is 192.168.0.4, use the wizard to easily define conditional expressions as "IP = 192.168.0.4".</li>
		<br><img alt="NM-add3" src="images/screenshots/data-tagging2.png" >	<br><br>
		<br><img alt="NM-add3" src="images/screenshots/data-tagging3.png" >	<br><br>
		 <li><b>To Add Multiple Tags On The Same Table</b> Click on the plus(+) sign and provide the details for the Tag.</li>		
		<li>Click on <b>next</b> to Schedule the data tag.</li>
		<br><img alt="NM-add3" src="images/screenshots/data-tagging3a.png" >	<br><br>
		<li><b>When do you want data tags to be applied</b>:</li>
			<ul>
				<li><b>On Ingest</b>: Tagging job will be performed while importing files to QueryIO.</li>
				<li><b>Post-Ingest</b>: Tagging job will be performed at chosen time intervals starting from a mentioned time.</li>
			</ul>
		<li><b>Apply this data tag to existing data</b>: If checked then the tag will be applied to existing data when specified.</li>
			<ul>
				<li><b>Apply Now</b>: Choose this to apply tag just after the data tag is defined.</li>
				<li><b>Schedule Time</b>: Choose this to apply tag on specified time.</li>
			</ul>
		<li><b>Processing Type for Existing Data or Post-Ingest Tagging</b>: For specific file types(csv, json, keyvalue, log, iislog,accesslog, and jtl), you can choose to process the file according to :</li>
			<ul>
				<li><b>File Level Processing</b>:  You can choose to process whole file together(recommended for multiple files of small size), a single mapper has lots of files.</li>
				<li><b>Record Level Processing</b>: Process records one by one(recommended for large files),multiple mappers are launched and processing is done record by record.</li>
			</ul>			
		<li>Click on <b>Add</b> to add newly created tag into tags list.</li>
		<img alt="NM-add3" src="images/screenshots/data-tagging4.png" >	<br><br>
		
		<li>Tag will be added to tags list and can be viewed in <b>Data > Data Tagging</b>.</li>
		
	</ul>
		<p>
			You can use <a href="big-data-import-export.html"> Data Import</a> to import data to the cluster and check the tags added in metadata table using <a href="hadoop-sql-designer.html"> Query Designer</a></p>
		<br />
		<hr align="center" class="whs4" />
		<h4 class="whs5">
			Copyright &copy; 2017 QueryIO Corporation. All Rights Reserved.</h4>
		<h4 class="whs5">
			QueryIO, &quot;Big Data Intelligence&quot; and the QueryIO Logo are trademarks of QueryIO Corporation. Apache, Hadoop and HDFS are trademarks of The Apache Software Foundation.</h4>
	</body>
</html>
